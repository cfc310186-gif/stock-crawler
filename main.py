print("âœ… æ­£åœ¨åŸ·è¡Œ main.py [v16.0 å‡æ—¥è‡ªå‹•ä¼‘æ¯ç‰ˆ]")

import requests
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import time
import datetime
import os
import random
import yfinance as yf
import re
import sys
from io import StringIO

# --- è¨­å®šå€ ---
SHEET_NAME = "Stock_Data"
JSON_FILE_NAME = "service_account.json"
BROKER_ID = "9A91" 

# --- ğŸ“… æ—¥æœŸæª¢æŸ¥èˆ‡è¨­å®š ---
def check_and_get_date():
    today = datetime.date.today()
    weekday = today.weekday() # 0=é€±ä¸€, ..., 5=é€±å…­, 6=é€±æ—¥
    
    if weekday == 5 or weekday == 6:
        day_str = "é€±å…­" if weekday == 5 else "é€±æ—¥"
        print(f"ğŸ˜´ ä»Šå¤©æ˜¯ {today} ({day_str})ï¼Œè‚¡å¸‚ä¸é–‹ç›¤ï¼Œç¨‹å¼è‡ªå‹•ä¼‘çœ ã€‚")
        sys.exit(0) # æ­£å¸¸çµæŸç¨‹å¼ (Exit Code 0)
    
    return today.strftime('%Y-%m-%d')

# å–å¾—ç›®æ¨™æ—¥æœŸ (å¦‚æœæ˜¯å‡æ—¥ï¼Œä¸Šé¢é‚£è¡Œå°±æœƒç›´æ¥çµæŸç¨‹å¼ï¼Œä¸æœƒå¾€ä¸‹è·‘)
TARGET_DATE_STR = check_and_get_date()
print(f"ğŸ“… ç›®æ¨™æ—¥æœŸ: {TARGET_DATE_STR} (å¹³æ—¥ï¼Œé–‹å§‹å·¥ä½œ)")

# --- ç›£æ§åå–® ---
WATCHLIST = [
    '3450', '3689', '3533', '3665', '3605', '3217', '6197', '3526', '6213',
    '6279', '3023', '3003', '2460', '6290', '3501',
    '2317', '2392', '5457', '6205', '3092', '2462', '3511',
    '6274', '2009', '2476', '1617'
]

def get_today_stock_list_from_fubon():
    print("ğŸ” æ­£åœ¨å¾å¯Œé‚¦è­‰åˆ¸æŠ“å–äº¤æ˜“åå–®...")
    
    # ç¶²å€æ‹¼æ¥
    base = "https://fubon-ebrokerdj.fbs.com.tw/z/zg/zgb/zgb0.djhtm"
    params_str = f"?a=9A00&b=0039004100390031&c=B&e={TARGET_DATE_STR}&f={TARGET_DATE_STR}"
    real_url = base + params_str
    
    print(f"   â˜ï¸ å¯¦éš›è«‹æ±‚ç¶²å€: {real_url}")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    try:
        res = requests.get(real_url, headers=headers, timeout=15)
        
        # å¼·åˆ¶ Big5 è§£ç¢¼
        try:
            raw_html = res.content.decode('big5', errors='ignore')
        except:
            raw_html = res.content.decode('cp950', errors='ignore')

        # Regex è§£æ (å…è¨± td å…§æœ‰ç©ºç™½)
        pattern = r"GenLink2stk\('AS(\d{4})','(.*?)'\);[\s\S]*?<td[^>]*>\s*([0-9,]+)\s*</td>[\s\S]*?<td[^>]*>\s*([0-9,]+)\s*</td>[\s\S]*?<td[^>]*>\s*(-?[0-9,]+)\s*</td>"
        
        matches = re.findall(pattern, raw_html)
        
        if not matches:
            print("âŒ Regex æ‰¾ä¸åˆ°è³‡æ–™ï¼Œè«‹ç¢ºèªä»Šæ—¥æ˜¯å¦ç‚ºäº¤æ˜“æ—¥æˆ–å ±è¡¨å°šæœªç”¢å‡ºã€‚")
            return []
            
        print(f"   ğŸ‰ æˆåŠŸæŠ“å–ï¼Regex æƒæåˆ° {len(matches)} ç­†è³‡æ–™")
        
        stock_data = []
        for match in matches:
            try:
                stock_id = match[0]
                stock_name = match[1]
                # match[4] æ˜¯å·®é¡(æ·¨è²·è³£)ï¼Œéœ€ç§»é™¤é€—è™Ÿ
                raw_net_amt = match[4].replace(',', '')
                net_amt_val = int(raw_net_amt) # å–®ä½å·²æ˜¯åƒå…ƒ
                
                stock_data.append({
                    'id': stock_id,
                    'name': stock_name,
                    'net_amt': net_amt_val
                })
            except:
                continue
        
        # å»é‡
        seen = set()
        unique_stocks = []
        for s in stock_data:
            if s['id'] not in seen:
                unique_stocks.append(s)
                seen.add(s['id'])
                
        print(f"âœ… è§£æå®Œæˆï¼ŒæŠ“åˆ° {len(unique_stocks)} æª”è‚¡ç¥¨ã€‚")
        return unique_stocks

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def get_close_price_fallback(stock_id):
    try:
        stock = yf.Ticker(f"{stock_id}.TW")
        hist = stock.history(period="1d")
        if not hist.empty:
            return float(hist.iloc[-1]['Close'])
        return 0.0
    except:
        return 0.0

def get_histock_details(stock_id, target_date_str):
    url = f"https://histock.tw/stock/brokertrace.aspx?bno={BROKER_ID}&no={stock_id}"
    cookie_val = os.environ.get("HISTOCK_COOKIE", "")
    headers = {"User-Agent": "Mozilla/5.0", "Cookie": cookie_val}

    try:
        time.sleep(random.uniform(1.0, 3.0)) 
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200: return None

        dfs = pd.read_html(StringIO(response.text))
        target_df = None
        for df in dfs:
            if "è²·é€²å‡åƒ¹" in df.columns and "æ—¥æœŸ" in df.columns:
                target_df = df
                break
        if target_df is None: return None

        found_row = None
        for index, row in target_df.iterrows():
            raw_date = str(row["æ—¥æœŸ"])
            formatted_date = raw_date.replace("/", "-")
            try:
                parts = formatted_date.split("-")
                if len(parts) == 3:
                    formatted_date = f"{parts[0]}-{int(parts[1]):02d}-{int(parts[2]):02d}"
            except: pass
                
            if formatted_date == target_date_str:
                found_row = row
                break
        
        if found_row is None: return None

        buy_vol = pd.to_numeric(found_row["è²·é€²å¼µæ•¸"], errors='coerce')
        sell_vol = pd.to_numeric(found_row["è³£å‡ºå¼µæ•¸"], errors='coerce')
        close_price = pd.to_numeric(found_row["æ”¶ç›¤åƒ¹"], errors='coerce')

        # æˆæœ¬è¨ˆç®—
        buy_avg = pd.to_numeric(found_row["è²·é€²å‡åƒ¹"], errors='coerce')
        sell_avg = pd.to_numeric(found_row["è³£å‡ºå‡åƒ¹"], errors='coerce')
        
        net_vol = int(buy_vol - sell_vol)
        total_buy_val = buy_vol * buy_avg
        total_sell_val = sell_vol * sell_avg
        net_amount_calc = total_buy_val - total_sell_val
        
        real_cost = 0.0
        if net_vol != 0:
            real_cost = round((net_amount_calc / net_vol), 1)
        else:
            real_cost = close_price

        # HiStock é‡‘é¡è½‰åƒå…ƒ
        net_amt_k = int(net_amount_calc / 1000)
        
        return {
            'date': target_date_str,
            'net_vol': net_vol, 
            'cost': real_cost, 
            'net_amt_k': net_amt_k
        }
        
    except Exception as e:
        return None

def update_google_sheet_overwrite(new_rows, target_date_str):
    scope = ["https://spreadsheets.google.com/feeds", 'https://www.googleapis.com/auth/drive']
    if not os.path.exists(JSON_FILE_NAME):
        if "GCP_CREDENTIALS" in os.environ:
            with open(JSON_FILE_NAME, "w") as f:
                f.write(os.environ["GCP_CREDENTIALS"])
        else:
            print("âŒ æ‰¾ä¸åˆ° service_account.json")
            return
    try:
        creds = ServiceAccountCredentials.from_json_keyfile_name(JSON_FILE_NAME, scope)
        client = gspread.authorize(creds)
        sheet = client.open(SHEET_NAME).sheet1
        
        print("ğŸ’¾ æ­£åœ¨è®€å– Google Sheet ç¾æœ‰è³‡æ–™...")
        all_values = sheet.get_all_values()
        
        if not all_values:
            header = ["æ—¥æœŸ", "ä»£è™Ÿ", "åç¨±", "è²·è³£åˆ¥", "è²·è³£è¶…é‡‘é¡(åƒ)", "æ”¶ç›¤åƒ¹", "ä¼°ç®—å¼µæ•¸"]
            final_data = [header] + new_rows
            sheet.update(final_data)
            print(f"âœ… å¯«å…¥å®Œæˆ (å…¨æ–°è³‡æ–™)ï¼å…± {len(new_rows)} ç­†")
            return

        header = all_values[0]
        old_data = all_values[1:]
        
        kept_data = []
        deleted_count = 0
        target_clean = target_date_str.replace("/", "-")
        
        for row in old_data:
            if not row: continue
            row_date = str(row[0]).replace("/", "-")
            
            if row_date != target_clean:
                kept_data.append(row)
            else:
                deleted_count += 1
                
        print(f"ğŸ§¹ å·²æ¸…é™¤ Sheet ä¸­ {deleted_count} ç­†èˆŠçš„ {target_date_str} è³‡æ–™ã€‚")
        
        final_data = [header] + kept_data + new_rows
        
        print(f"ğŸ’¾ æ­£åœ¨å›å¯« Google Sheet (ç¸½ç­†æ•¸: {len(final_data)-1})...")
        sheet.clear()
        sheet.update(final_data)
        print("âœ… æ›´æ–°æˆåŠŸï¼")

    except Exception as e:
        print(f"âŒ Google Sheet å¯«å…¥å¤±æ•—: {e}")

def main():
    print("ğŸš€ å•Ÿå‹• main() ä¸»ç¨‹å¼...")
    stock_list = get_today_stock_list_from_fubon()
    if not stock_list: return

    all_data = []
    
    print(f"ğŸ“ æº–å‚™åˆ†æ {len(stock_list)} æª”è‚¡ç¥¨ (ç›®æ¨™æ—¥æœŸ: {TARGET_DATE_STR})...")
    
    for i, stock_info in enumerate(stock_list):
        stock_id = stock_info['id']
        stock_name = stock_info['name']
        fubon_net_amt = stock_info['net_amt'] 
        
        print(f"[{i+1}/{len(stock_list)}] åˆ†æ {stock_name} ({stock_id})...", end="\r")
        
        final_date = TARGET_DATE_STR
        final_net_amt_k = fubon_net_amt
        final_cost = 0.0
        final_vol = 0
        
        is_precise_data = False
        if stock_id in WATCHLIST:
            data = get_histock_details(stock_id, TARGET_DATE_STR)
            if data:
                final_date = data['date']
                final_net_amt_k = data['net_amt_k']
                final_cost = data['cost']
                final_vol = data['net_vol']
                is_precise_data = True
        
        if not is_precise_data:
            final_cost = get_close_price_fallback(stock_id)
            final_vol = int(final_net_amt_k / final_cost) if final_cost > 0 else 0

        bs_type = "è²·è¶…" if final_net_amt_k > 0 else "è³£è¶…"
        if final_net_amt_k == 0: bs_type = "å¹³ç›¤"

        row_data = [
            final_date,
            stock_id,
            stock_name,
            bs_type,
            final_net_amt_k,
            final_cost,
            final_vol
        ]

        all_data.append(row_data)
        
    print(f"\nâœ… åˆ†æå®Œæˆï¼Œå…± {len(all_data)} ç­†ã€‚")
    if all_data:
        all_data.sort(key=lambda x: abs(x[4]), reverse=True)
        update_google_sheet_overwrite(all_data, TARGET_DATE_STR)

if __name__ == "__main__":
    main()